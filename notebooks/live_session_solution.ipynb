{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "student_notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datacamp/Brand-Analysis-using-Social-Media-Data-in-R-Live-Training/blob/master/notebooks/live_session_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJYbvo8eV-Rd",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/datacamp/r-live-training-template/blob/master/assets/datacamp.svg?raw=True\" alt = \"DataCamp icon\" width=\"50%\">\n",
        "</p>\n",
        "<br><br>\n",
        "\n",
        "# **Brand Analysis Using Social Media Data in R**\n",
        "\n",
        "Welcome to this hands-on training where you will learn how to perform brand analysis from social media data using R. We will be using different R libraries to analyze twitter data and derive insights.\n",
        "\n",
        "In this session, you will learn\n",
        "\n",
        "* How to compare brand popularity by extracting and comparing follower counts\n",
        "* How to promote a brand by identifying popular tweets\n",
        "* How to evaluate brand salience and compare the same for two brands using tweet frequencies\n",
        "* Understand brand perception through text mining and by visualizing key terms\n",
        "* Perform sentiment analysis to understand customer's feelings and sentiments about a brand\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7FkSxuXPwVv",
        "colab_type": "text"
      },
      "source": [
        "## **The Dataset**\n",
        "\n",
        "The datasets to be used in this training session are in CSV format. These datasets comprise extracted live tweets using `rtweet` library. The datasets are:\n",
        "* **users_twts.csv**: User data of four twitter accounts pre-extracted from Twitter\n",
        "* **tesladf.csv**: Tweets searched on keyword 'tesla' pre-extracted from Twitter\n",
        "* **toyotadf.csv**: Tweets searched on keyword 'toyota' pre-extracted from Twitter\n",
        "* **tesla_small.csv**: Tweets searched on keyword 'tesla' pre-extracted from Twitter. This is a smaller dataset with fewer tweets.\n",
        "\n",
        "\n",
        "Note that we will not be extracting live tweets from Twitter during this session as it invovles a setup process. We will be using pre-extracted tweets saved in RDS format.\n",
        "\n",
        "- **users_twts.csv**: has 4 records and 90 columns of user data and associated metadata\n",
        "- **tesladf.csv**: has 17979 records (tweets) and 90 columns of tweet text and associated metadata\n",
        "- **toyotadf.csv**: has 17798 records (tweets) and 90 columns of tweet text and associated metadata\n",
        "- **tesla_small.csv**: has 500 records (tweets) and 90 columns of tweet text and associated metadata\n",
        "\n",
        "All the datasets have the same set of columns and some of the important columns that we will work with are listed below:\n",
        "\n",
        "- `user_id`: Twitter allocated unique ID for each twitter user.\n",
        "- `created_at`: UTC time when this Tweet was created\n",
        "- `screen_name`: The screen name or twitter handle that an user identifies themselves with\n",
        "`text`: The actual tweet text posted by an user\n",
        "- `retweet_count`: Number of times a given tweet has been retweeted.\n",
        "- `followers_count`: The number of followers a twitter account currently has."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpzJ3VfAP8hO",
        "colab_type": "text"
      },
      "source": [
        "## **Getting started and installing packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUKG6fNMV_zf",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Install R Packages\n",
        "system('apt-get install r-cran-httpuv r-cran-rtweet r-cran-reshape r-cran-qdapregex r-cran-tm r-cran-qdap')\n",
        "install.packages('syuzhet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bDm1UJHQGGO",
        "colab_type": "text"
      },
      "source": [
        "## **1. Compare brand popularity by extracting and comparing follower counts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-NGEGn1QMMe",
        "colab_type": "text"
      },
      "source": [
        "We can compare followers count for competing products by using their screen names and follower counts.\n",
        "\n",
        "Note:\n",
        "- `screen_name`: The screen name or twitter handle that an user identifies themselves with.\n",
        "- `followers_count`: The number of followers a twitter account currently has.\n",
        "\n",
        "The followers count for a twitter account indicates the popularity of that account and is a measure of social media influence.\n",
        "\n",
        "To extract user data directly from twitter, we usually load the `rtweet` package, obtain and create Twitter API access tokens according to the instructions in this [article](https://rtweet.info/articles/auth.html) and extract user data with the `lookup_users()` function which takes screen names as input and extracts user data from twitter accounts.\n",
        "\n",
        "```R\n",
        "# Store name of users to extract data on twitter accounts of 4 auto magazines\n",
        "users <- c(\"caranddriver\", \"motortrend\", \"autoweekUSA\", \"roadandtrack\")\n",
        "\n",
        "# Extract user data for the twitter accounts stored in users\n",
        "users_twts <- lookup_users(users)\n",
        "\n",
        "# Save extracted data as a CSV file using `fwrite()` from`data.table` library\n",
        "fwrite(users_twts, file = \"users_twts.csv\")\n",
        "```\n",
        "\n",
        "To avoid setting up individual API access tokens, we will be directly using a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brr08aZX9Wss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load rtweet library\n",
        "library(rtweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-MPrmAQW_x",
        "colab_type": "text"
      },
      "source": [
        "Import the pre-saved CSV file with extracted user data for the four twitter accounts\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VJyZeEo9M4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import extracted user data from the csv file into a dataframe\n",
        "users_twts = read.csv(\"https://github.com/datacamp/Brand-Analysis-using-Social-Media-Data-in-R-Live-Training/blob/master/data/users_twts.csv?raw=true\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApykRattQbKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View dimensions of the dataframe\n",
        "dim(users_twts)\n",
        "\n",
        "# View few rows of the dataframe\n",
        "head(users_twts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLV7RTa0Qgn7",
        "colab_type": "text"
      },
      "source": [
        "From the user data, extract details of screen names and follower counts for the 4 twitter accounts into a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PSYuZrRQdDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a data frame of screen names and followers count\n",
        "user_df <- users_twts[,c(\"screen_name\",\"followers_count\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shUF9Rb0Qj1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display and compare the follower counts for the 4 twitter accounts\n",
        "user_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkZ6_UufQmDo",
        "colab_type": "text"
      },
      "source": [
        "#### We can see that \"Car and Driver\" is the most popular automobile magazine with number of followers exceeding a million and it is followed by \"Motor Trends\" with 739,800 followers. \n",
        "\n",
        "#### An automobile brand advertising for a new model can place its adverts on the homepage of these twitter acocunts or tag these twitter accounts while promoting its brand. \n",
        "\n",
        "#### Thus, Digital marketers can position ads on popular twitter accounts for increased visibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5SCnmlhQvXK",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<center><h1> Q&A 1</h1> </center>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G77V4hunQ6mn",
        "colab_type": "text"
      },
      "source": [
        "## **2. Promote a brand by identifying popular tweets using retweet counts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P2iRV9bRCFF",
        "colab_type": "text"
      },
      "source": [
        "To extract tweet data for a particular term, we can use the `search_tweets()` function from `rtweet` library which has the following arguments:\n",
        "\n",
        "*\t`q`: The query being used, for example `\"tesla\"`\n",
        "\n",
        "*\t`n`: The number of tweets\n",
        "\n",
        "*\t`lang`: The language of the tweet - here set to `\"en\"`\n",
        "\n",
        "*\t`include_rts`: A boolean value that either accepts the inclusion of retweets or not on resulting data\n",
        "\n",
        "In this notebook, we will be using a CSV file to import the tweets but using `search_tweets()` to extract tweets on `\"tesla\"` can be done as such.\n",
        "\n",
        "```R\n",
        "# Extract 18000 tweets on Tesla\n",
        "tweets_tesla = search_tweets(\"tesla\", n = 18000, lang = \"en\", include_rts = FALSE)\n",
        "\n",
        "fwrite(tweets_tesla, \"tesladf.csv\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVr2K61LRLxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import extracted tweets on \"tesla\" in CSV format into a dataframe\n",
        "tesladf = read.csv(\"https://github.com/datacamp/Brand-Analysis-using-Social-Media-Data-in-R-Live-Training/blob/master/data/tesladf.csv?raw=true\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "occyqLL8ROTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Explore the tweet dataframe\n",
        "dim(tesladf)\n",
        "head(tesladf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYqi0uR_RUpL",
        "colab_type": "text"
      },
      "source": [
        "Extract the columns `retweet_count` and `text` and save to a new dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGiPgxHCRXBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a data frame of tweet text and retweet count\n",
        "rtwt <- tesladf[,c(\"text\", \"retweet_count\")]\n",
        "\n",
        "# View few rows of the new dataframe\n",
        "head(rtwt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Fe8R4MRZq5",
        "colab_type": "text"
      },
      "source": [
        "Sort in descending order of the retweet counts using `arrange()` from `dplyr` library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENDjlFu2Rfdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import library\n",
        "library(dplyr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMeJnJE-Rhhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort data frame based on descending order of retweet counts\n",
        "rtwt_sort <- arrange(rtwt, desc(retweet_count))\n",
        "\n",
        "# View sorted output\n",
        "head(rtwt_sort)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztU_tU0tRkC9",
        "colab_type": "text"
      },
      "source": [
        "The `text` column usually contains duplicate tweets. To get unique tweets, we can use the `unique()` function which has 2 arguments:\n",
        "\n",
        "* the data frame being used\n",
        "* `by`: which columns to search for unique values in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkgUS677RoHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exclude rows with duplicate text from sorted data frame\n",
        "rtwt_unique <- unique(rtwt_sort, by = \"text\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHqPsFYcRqbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print top 6 unique posts retweeted most number of times\n",
        "head(rtwt_unique)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HjCcW3YRtT2",
        "colab_type": "text"
      },
      "source": [
        "#### The most retweeted texts have popular quotes such as \"I think I want a Tesla\", indicating the loyalty of Tesla fans.\n",
        "\n",
        "#### These tweets can be used for promoting Tesla's models and brand loyalty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHzr8Hn4R_C6",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<center><h1> Q&A 2</h1> </center>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXApXp8zSEjO",
        "colab_type": "text"
      },
      "source": [
        "## **3.\tEvaluate brand salience and compare the same for two brands using tweet frequencies**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNDACnEuSIEr",
        "colab_type": "text"
      },
      "source": [
        "Brand salience is the extent to which a brand is continuously talked about.\n",
        "\n",
        "Monitoring tweets on a certain brand over time is an excellent proxy to brand salience. Here, we will compare how tweets mentioning Tesla vs Toyota are present over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy4a7fzRSOJM",
        "colab_type": "text"
      },
      "source": [
        "#### **3a) Visualizing frequency of tweets using time series plots**\n",
        "\n",
        "Let's first visualize tweet frequency on the automobile brand \"Tesla\". We will be using the tweet dataframe created for Tesla in the previous exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKbHd9FZSVHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the tweet dataframe\n",
        "head(tesladf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGxwYMw0SX_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the `created_at` column in the tweet dataframe\n",
        "head(tesladf$created_at,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC4D25iKSeDH",
        "colab_type": "text"
      },
      "source": [
        "We see the `created_at` column has the timestamp that we'd need to convert to the correct date format using `as.POSIXct()` which takes in:\n",
        "\n",
        "* The column being converted\n",
        "* `format`: The date format - here to be `\"%Y-%m-%dT%H:%M:%SZ\"`\n",
        "* `tz`: The time-zone of the conversion\n",
        "\n",
        "Inputs for `format` argument to convert date-time format:\n",
        "\n",
        "<p align=\"left\">\n",
        "\n",
        "<img src=\"https://github.com/datacamp/Brand-Analysis-using-Social-Media-Data-in-R-Live-Training/blob/master/data/striptime.png?raw=true\" alt = \"\" width=\"40%\">\n",
        "\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nBlu8flSjMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update dates in `created_at` column with the new date format\n",
        "tesladf$created_at <- as.POSIXct(tesladf$created_at, format = \"%Y-%m-%dT%H:%M:%SZ\", tz = \"GMT\")\n",
        "\n",
        "# View the `created_at` column again\n",
        "head(tesladf$created_at, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE5XKTTVSmdF",
        "colab_type": "text"
      },
      "source": [
        "To visualize tweets over time, we will use the `rtweet` library's `ts_plot()` function which takes in:\n",
        "* The data frame being plotted\n",
        "* `by`: The time interval - here `'hours'`\n",
        "* `color`: The color of the line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEdV3m6bSpcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a time series plot\n",
        "ts_plot(tesladf, by = \"hours\", color = \"blue\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxEelOtlSr3p",
        "colab_type": "text"
      },
      "source": [
        "We see tweets for Tesla fluctuating from high to low and then reaching a high again between 17 and 18 May after a big dip on 17 May. The high number of tweets could be related to an event or topic about Tesla's products."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xb92cH6Sv6d",
        "colab_type": "text"
      },
      "source": [
        "#### **3b) Compare brand salience for two brands using time series plots and tweet frequencies**\n",
        "\n",
        "Let's compare how tweets mentioning `\"Toyota\"` compare against `\"Tesla\"` - here is the `search_tweets()` code used to get tweets on `\"Toyota\"`\n",
        "\n",
        "```R\n",
        "# Extract tweets for Toyota using `search_tweets()`\n",
        "\n",
        "tweets_toyo = search_tweets(\"toyota\", n = 18000, lang = \"en\",  include_rts = FALSE)\n",
        "\n",
        "fwrite(tweets_toyo, file = \"toyotadf.csv\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQl0RsYAS1Tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import extracted tweets on `\"toyota\"` in CSV format\n",
        "toyotadf = read.csv(\"https://github.com/datacamp/Brand-Analysis-using-Social-Media-Data-in-R-Live-Training/blob/master/data/toyotadf.csv?raw=true\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii0j6PNuS5jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Explore the tweet dataframe for toyota\n",
        "dim(toyotadf)\n",
        "head(toyotadf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi5_Osd_S7SI",
        "colab_type": "text"
      },
      "source": [
        "We can see the extracted tweets on `toyota` and the `created_at` column has the timestamp."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMSprIbMS9bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update dates in `created_at` column with the new date format\n",
        "toyotadf$created_at <- as.POSIXct(toyotadf$created_at, format = \"%Y-%m-%dT%H:%M:%SZ\", tz = \"GMT\")\n",
        "\n",
        "# View the `created_at` column again\n",
        "head(toyotadf$created_at, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTaiviEmTAcn",
        "colab_type": "text"
      },
      "source": [
        "To visualize the number of tweets over time, we aggregate both `toyotadf` and `tesladf` into time series objects using `ts_data()` which takes in 2 arguments:\n",
        "* The data frame being converted\n",
        "* `by`: The time interval of frequency counting (here `'hours'`)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrimCCi7TFS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a time series object for Tesla at hourly intervals\n",
        "tesla_ts <- ts_data(tesladf, by ='hours')\n",
        "\n",
        "# View the time series object\n",
        "head(tesla_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmweHZYBTH_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rename the two columns in the time series object\n",
        "names(tesla_ts) <- c(\"time\", \"tesla_n\")\n",
        "\n",
        "# View the output\n",
        "head(tesla_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76A7WumhTKfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a time series object for Toyota at hourly intervals\n",
        "toyo_ts <- ts_data(toyotadf, by ='hours')\n",
        "\n",
        "# Rename the two columns in the time series object\n",
        "names(toyo_ts) <- c(\"time\", \"toyo_n\")\n",
        "\n",
        "# View the output\n",
        "head(toyo_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6RUzz0qTN2B",
        "colab_type": "text"
      },
      "source": [
        "We now have two time series objects with columns for time and tweet frequencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q4mBBzATR2u",
        "colab_type": "text"
      },
      "source": [
        "Merge the objects into a single data frame using the `merge()` function which is from the `reshape` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8M0CeJYTVGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the required libraries\n",
        "library(reshape)\n",
        "library(ggplot2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G89nd427TYde",
        "colab_type": "text"
      },
      "source": [
        "The `merge()` function takes 3 arguments:\n",
        "\n",
        "* the time series objects to be merged \n",
        "\n",
        "* `by` argument which specifies the common column for merging\n",
        "\n",
        "* `all` argument to instruct whether all the rows should be included"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBydhT-TcRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merge the time series objects with \"time\" as the common column\n",
        "merged_df <- merge(tesla_ts, toyo_ts, by = \"time\", all = TRUE)\n",
        "\n",
        "# View few rows of the merged dataframe\n",
        "head(merged_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn4Sv3i5Tey8",
        "colab_type": "text"
      },
      "source": [
        "We can see the tweet frqeuencies for tesla and toyota in separate columns.\n",
        "\n",
        "Stack the tweet frequency counts into a single column and brands into another column using `melt()` from `reshape` library.\n",
        "\n",
        "The `melt()` function takes 3 arguments:\n",
        "\n",
        "* the dataframe to melt \n",
        "\n",
        "* `na.rm` to specify whether to include or exclude rows with missing values\n",
        "* `id.vars` to specify the source columns to be retained (`time` in this case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQuPdnVSTjhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stack the tweet frequency columns\n",
        "melt_df <- melt(merged_df, na.rm = TRUE, id.vars = \"time\")\n",
        "\n",
        "# View the output\n",
        "head(melt_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV8B_xyHTl8d",
        "colab_type": "text"
      },
      "source": [
        "We can see that all columns other than `time` have been stacked and we have three columns now: `time`, `variable`, `value`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-kZEbeATpE5",
        "colab_type": "text"
      },
      "source": [
        "Plot the frequency of tweets on Tesla and Toyota using `ggplot()`.\n",
        "\n",
        "Set the relevant column names i.e.  as values for the x-axis, y-axis, and color of the plot.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNvRqE1oTrsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Compare brand salience by plotting the frequency of tweets\n",
        "\n",
        "# Plot frequency of tweets on Tesla and Toyota\n",
        "ggplot(data = melt_df, aes(x = time, y = value, col = variable))+\n",
        "  geom_line(lwd = 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPdxRmjXTvJZ",
        "colab_type": "text"
      },
      "source": [
        "#### It's interesting to see that there are relatively more tweets on Tesla than on Toyota. \n",
        "\n",
        "#### The higher level of tweet activity for Tesla indicates a stronger brand salience for Tesla than Toyota. \n",
        "\n",
        "#### Visualizing tweets through time series analysis provides good insights on interest level on a product and can be used to compare brand salience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuXL2tVYTyMU",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<center><h1> Q&A 3</h1> </center>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pouUUHJT0kg",
        "colab_type": "text"
      },
      "source": [
        "## **4. Understand brand perception through text mining and by visualizing key terms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xib3Ie4fT49f",
        "colab_type": "text"
      },
      "source": [
        "One of the most important and common tasks in social media data analysis is being able to understand what users are tweeting about the most and how they perceive a particular brand. \n",
        "\n",
        "In this section, we will visualize the most common words mentioning `\"Tesla\"` to build a word cloud that showcases the most common words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw6-EWV8XFMq",
        "colab_type": "text"
      },
      "source": [
        "### **4a) Processing tweets and twitter data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VB60JqrXJlv",
        "colab_type": "text"
      },
      "source": [
        "Tweets are unstructured, noisy, and raw, and properly processing them is essentially to accurately capture useful brand-perception information. \n",
        "\n",
        "Here are some processing steps we will be performing:\n",
        "* Step 1: Remove URLs from text\n",
        "* Step 2: Remove special characters, punctuations, and numbers\n",
        "* Step 3: Convert the text to a Corpus (i.e. large document of text)\n",
        "* Step 4: Convert all letters in the Corpus to lower case\n",
        "* Step 5: Remove common words (the, a, and ...), also called stop words, from the Corpus\n",
        "* Step 6: Remove custom stop words from the Corpus\n",
        "* Step 7: Trim leading and trailing spaces from Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmJ5jmE_XNom",
        "colab_type": "text"
      },
      "source": [
        "First, extract the tweets stored in the `text` column of the tweet dataframe for Tesla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI0tMduSXRfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract tweet text from the Tesla dataset\n",
        "twt_txt <- tesladf$text\n",
        "head(twt_txt, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gFwy6G7XUT_",
        "colab_type": "text"
      },
      "source": [
        "We can see the first few rows of tweet text extracted from the main dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at-r_kOVbGu9",
        "colab_type": "text"
      },
      "source": [
        "**Step 1: Remove URLs from text**\n",
        "\n",
        "Use the `rm_twitter_url()` function from the `qdapRegex` library to remove all URLs from the text.\n",
        "\n",
        "`rm_twitter_url()` takes the tweet text dataframe as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6slF68kxXZV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the library\n",
        "library(qdapRegex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di7qnAiHXbUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove URLs from the tweet text and view the output\n",
        "twt_txt_url <- rm_twitter_url(twt_txt)\n",
        "\n",
        "# View few rows of the dataframe\n",
        "head(twt_txt_url, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuXepDP-Xdam",
        "colab_type": "text"
      },
      "source": [
        "The URLs are removed from tweets: check records starting with \"This article says VW beat Tesla...\" and \"Anyone up for some...\" for example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPxOCiT_XhSw",
        "colab_type": "text"
      },
      "source": [
        "**Step 2: Remove special characters, punctuations, and numbers**\n",
        "\n",
        "To remove special characters, punctuations, and numbers, we will use the `gsub()` function which takes in:\n",
        "\n",
        "* The pattern to search for - for example, if we are searching for non-numbers and non-letters, the regular expression `\"[^A-Za-z]\"` is a pattern\n",
        "* The character to replace it with\n",
        "* The text source here `twt_txt_url`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SjJS0HIXj0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace special characters, punctuation, & numbers with spaces\n",
        "twt_txt_chrs  <- gsub(\"[^A-Za-z]\",\" \" , twt_txt_url)\n",
        "\n",
        "# View text after replacing special characters, punctuation, & numbers\n",
        "head(twt_txt_chrs, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_-kJafWXl3L",
        "colab_type": "text"
      },
      "source": [
        "In the output, we can see that all content other than letters has been replaced with spaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPpNoWGDXn4B",
        "colab_type": "text"
      },
      "source": [
        "**Step 3: Building a Corpus**\n",
        "\n",
        "A Corpus is a list of text documents and is often used in text processing functions. To create a corpus, we will be using the `tm` library and the functions `VectorSource()` and `Corpus()`. The `VectorSource()` converts the tweet text to a vector of texts and the `Corpus()` function takes the output of `VectorSource()` and converts to a Corpus. An example on a tweets object would be:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMHWRCpzXxtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert processed text to a text corpus and view output\n",
        "library(tm)\n",
        "\n",
        "twt_corpus <- twt_txt_chrs %>% \n",
        "                VectorSource() %>% \n",
        "                Corpus() \n",
        "\n",
        "head(twt_corpus$content, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liHUvH9cXzve",
        "colab_type": "text"
      },
      "source": [
        "The text is stored under `content` within the corpus just created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5LvD2_ZX2YN",
        "colab_type": "text"
      },
      "source": [
        "**Step 4: Convert Corpus to lower case**\n",
        "\n",
        "To have all words in our corpus being uniform, we will lower all words in the Corpus to lower case (`'Tesla'` vs `'tesla'`). To do this, will use the `tm_map()` function which applies a transformation to the corpus. In this case, it takes in 2 arguments:\n",
        "* The corpus being transformed\n",
        "* The transformation itself, stored in the `tolower()` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN4kpViqX5U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the corpus to lowercase\n",
        "twt_corpus_lwr <- tm_map(twt_corpus, tolower) \n",
        "\n",
        "# View the corpus after converting to lowercase\n",
        "head(twt_corpus_lwr$content, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A2Ade6QX7SJ",
        "colab_type": "text"
      },
      "source": [
        "All characters in the corpus are now converted to lowercase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8zikMwjX-ko",
        "colab_type": "text"
      },
      "source": [
        "**Step 5:  Remove stop words from the Corpus**\n",
        "\n",
        "Stop words are commonly used words like `\"a\"`, `\"an\"`, `\"the\"` etc. They are often the most common words and tend to skew your analysis if left in the corpus. \n",
        "\n",
        "We will remove English stop words from the Corpus by using `tm_map()`which takes in this case 3 arguments:\n",
        "* The corpus being transformed\n",
        "* The transformation itself, stored in `removeWords()`\n",
        "* The English stop words to be removed, stored in `stopwords(\"english\")`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUJ7XhKxYCM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove English stop words from the corpus and view the corpus\n",
        "twt_corpus_stpwd <- tm_map(twt_corpus_lwr, removeWords, stopwords(\"english\"))\n",
        "\n",
        "# View the content column\n",
        "head(twt_corpus_stpwd$content, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPwQY3eiYD5X",
        "colab_type": "text"
      },
      "source": [
        "The common stop words are now removed from the corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9M80t89YG0F",
        "colab_type": "text"
      },
      "source": [
        "**Step 6: Remove custom stop words from the Corpus**\n",
        "\n",
        "In the corpus, frequently appearing terms like `tesla`, `sure`, `can`, `will`  etc do not add any value for analysis and can be removed to create a meaningul, refined corpus.\n",
        "\n",
        "To do this, first extract a list of most frequent terms and their number of occurrences (also called term frequency) using the `freq_terms()` function from `qdap` library. `freq_terms()` takes two arguments: \n",
        "* The corpus \n",
        "* The top `\"n\"` terms to be extracted based on the number of occurrences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_COWKSPYKYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the library qdap\n",
        "library(qdap)\n",
        "\n",
        "# Extract term frequencies for top 60 words in the Corpus and view the output\n",
        "termfreq  <-  freq_terms(twt_corpus_stpwd, 60)\n",
        "\n",
        "termfreq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVBGt8MZYMgn",
        "colab_type": "text"
      },
      "source": [
        "We can see high frequencies for custom stop words like `tesla`, `s`, `t`, `elon` (`elon musk` is retained).\n",
        "\n",
        "Create of vector of such high frequency custom stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFRwFPcFYPKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a vector of custom stop words\n",
        "custom_stopwds <- c(\"tesla\", \"s\", \"t\", \"will\", \"elon\", \"can\", \"like\", \n",
        "\t\t\t\t\"just\", \"musk\", \"one\", \"m\",  \"get\", \"now\", \"cars\", \"amp\", \n",
        "                \"re\", \"go\", \"even\", \"via\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6ECamWIYSCr",
        "colab_type": "text"
      },
      "source": [
        "Apply `tm_map()` and `removeWords()` functions on the corpus to remove the custom stop words. `tm_map()` takes 3 arguments: \n",
        "* The corpus\n",
        "* `removeWords()`\n",
        "* The vector of custom stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgBvhDpYVvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove custom stop words and create a refined corpus\n",
        "twt_corpus_stpwd2 <- tm_map(twt_corpus_stpwd, removeWords, custom_stopwds)\n",
        "\n",
        "# View the text corpus after removing custom stop words\n",
        "head(twt_corpus_stpwd2$content, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtoUm-K8YXto",
        "colab_type": "text"
      },
      "source": [
        "You can see that the corpus now has only important terms as the common and user-defined custom stop words have been removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht9KVArxYZhp",
        "colab_type": "text"
      },
      "source": [
        "Check the frequently occuring top 60 words again to see if we get a different list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0RCtWySYkAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract term frequencies for the top 60 words\n",
        "termfreq_clean <- freq_terms(twt_corpus_stpwd2, 60)\n",
        "\n",
        "# View the output\n",
        "termfreq_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZQmUb15YmqX",
        "colab_type": "text"
      },
      "source": [
        "**Step 7: Trim leading and trailing spaces from Corpus**\n",
        "\n",
        "To remove additional spaces and create a clean corpus, use the `tm_map()` which takes two arguments: \n",
        "\n",
        "* The Corpus\n",
        "* `stripWhitespace()` which collapses multiple spaces to a single space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa8PPh3xYpRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove additional spaces from the corpus\n",
        "corp_refined <- tm_map(twt_corpus_stpwd2, stripWhitespace)\n",
        "\n",
        "# View the text corpus after removing spaces\n",
        "head(corp_refined$content, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8GO0-hqYrjX",
        "colab_type": "text"
      },
      "source": [
        "The additional spaces are now removed from the corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9qBB5QOYtyo",
        "colab_type": "text"
      },
      "source": [
        "### **4b) Visualizing brand perception**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cVioms6Ywbx",
        "colab_type": "text"
      },
      "source": [
        "The most frequently used words in tweets are typically popular terms relevant to the topic tweeted.\n",
        "\n",
        "In this exercise, we will extract and visualize popular terms in our refined corpus using the word cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erhk544FY20z",
        "colab_type": "text"
      },
      "source": [
        "**Identify top 15 words spoken about the brand**\n",
        "\n",
        "Extract and view the term frequency for the top 15 words from the refined corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191I1eTtY6JU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract term frequencies for the top 15 words\n",
        "termfreq_15w <- freq_terms(corp_refined, 15)\n",
        "termfreq_15w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npmoJqaPY84c",
        "colab_type": "text"
      },
      "source": [
        "The popular terms related to tweets on Tesla can be seen here.\n",
        "\n",
        "The brand promotion team can analyze these terms to understand the pulse of the audience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcD8vAXVY_Jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Identify terms with more than 60 counts from the top 15 list\n",
        "term60 <- subset(termfreq_15w, FREQ > 60)\n",
        "term60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPkRyqdhZBbQ",
        "colab_type": "text"
      },
      "source": [
        "**Visualize popular terms with word clouds**\n",
        "\n",
        "A word cloud is an image made up of words in which the size of each word indicates its frequency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcCxKHfQZDs6",
        "colab_type": "text"
      },
      "source": [
        "The `wordcloud()` function from the `wordcloud` library is used to create word clouds and it takes the following arguments:\n",
        "\n",
        "* The Corpus\n",
        "* `min.freq` set to include only terms with a minimum frequency\n",
        "* `color` set to \"red\"\n",
        "* `scale` set to the range of font sizes\n",
        "* `random.order` set to FALSE to fix the word pattern in the word cloud\n",
        "\n",
        "The `RColorBrewer()` library provides some interesting color palettes to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI3ienvJZGEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libraries\n",
        "library(wordcloud)\n",
        "library(RColorBrewer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dQpHum2ZHbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a word cloud in red with min frequency of 100\n",
        "wordcloud(corp_refined, min.freq = 100, colors = \"red\", \n",
        "          scale = c(3,0.5),random.order = FALSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giOSp9oqZI7l",
        "colab_type": "text"
      },
      "source": [
        "A word cloud highlighting high-frequency words in large font sizes is displayed as output.\n",
        "\n",
        "We can see that 'elonmusk' stands out as the most popular term. Also, terms like 'car', 'buy', 'spacex' are the other popular ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSYL89y6ZK1x",
        "colab_type": "text"
      },
      "source": [
        "We can choose a color palette from the `RColorBrewer` library to make the word cloud colorful.\n",
        "\n",
        "Assign \"6\" colors from the “Dark2” palette of `brewer.pal()` and set the `max.words` argument to \"50\" to plot a word cloud of the top 50 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H4mPG9LZM8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create word cloud with 6 colors and max 50 words\n",
        "wordcloud(corp_refined, max.words = 50, \n",
        "          colors = brewer.pal(6, \"Dark2\"), \n",
        "          scale=c(4,1), random.order = FALSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vPQG8NNZPAV",
        "colab_type": "text"
      },
      "source": [
        "#### We now have an interesting word cloud depicting popular terms from tweets on Tesla positioned at the centre of the word cloud to highlight their relevance and importance.\n",
        "\n",
        "#### One can use word cloud as an effective promotional image for marketing campaigns as it communicates the brand messaging and highlights popular terms to convey the value of the content being shared."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8DhGVgRZRme",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<center><h1> Q&A 4</h1> </center>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJG8K9BCZTty",
        "colab_type": "text"
      },
      "source": [
        "## 5.\t**Further understanding brand perception by analyzing tweet sentiments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqlQ2F98ZWJd",
        "colab_type": "text"
      },
      "source": [
        "Sentiment analysis is the process of retrieving information about a consumer's perception of a product or brand.\n",
        "\n",
        "It is used to extract and quantify positive, negative, and neutral opinions as well as emotions like trust, joy, and anger from the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikCuc1N7ZYuC",
        "colab_type": "text"
      },
      "source": [
        "Steps involved in performing sentiment analysis:\n",
        "\n",
        "* Step 1: Extract tweets on topic of interest\n",
        "\n",
        "* Step 2: Extract sentiment scores from tweet text\n",
        "\n",
        "* Step 3: Visualize sentiment scores and interpret customer perceptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEiSxfR1Zb4E",
        "colab_type": "text"
      },
      "source": [
        "**Step 1: Extract tweets on topic of interest**\n",
        "\n",
        "To explore customer's sentiments on Tesla, import a smaller tweet dataset extracted from Twitter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krpO0mXPZd9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a smaller dataset for tesla\n",
        "tesladf_small <- read.csv(\"https://github.com/datacamp/Brand-Analysis-using-Social-Media-Data-in-R-Live-Training/blob/master/data/tesla_small.csv?raw=true\", stringsAsFactors=FALSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdN82t4QZqiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Explore the tweet dataframe\n",
        "dim(tesladf_small)\n",
        "head(tesladf_small)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mszFQYzPZrol",
        "colab_type": "text"
      },
      "source": [
        "We can see that this dataset has 500 tweets on Tesla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQTn66M2ZwaK",
        "colab_type": "text"
      },
      "source": [
        "**Step 2: Extract sentiment scores from tweet text**\n",
        "\n",
        "The `get_nrc_sentiment()` function from the `syuzhet` package is used to extract sentiment scores for the text and it takes the column storing the tweet text as the argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N_CxYC5Zufp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load library\n",
        "library(syuzhet)\n",
        "\n",
        "# Perform sentiment analysis for tweets on `Climate change` \n",
        "sa.value <- get_nrc_sentiment(tesladf_small$text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNy7G5PcZ0Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the sentiment scores for first 10 tweets\n",
        "head(sa.value, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyUNb1RrZ2Lu",
        "colab_type": "text"
      },
      "source": [
        "The sentiment scores for the first 10 records are displayed here with the rows and columns representing the tweets and the emotions respectively. \n",
        "\n",
        "The column values are the sentiment scores for the tweets against each emotion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h02dpSDZ4mC",
        "colab_type": "text"
      },
      "source": [
        "Get the sum of the sentiment scores for each emotion using `colSums()` and convert the output to a dataframe. `colSums()` takes the extracted sentiment scores as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7j5kvVWZ6pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate sum of sentiment scores\n",
        "score <- colSums(sa.value[,])\n",
        "\n",
        "# Convert the sum of scores to a dataframe\n",
        "score_df <- data.frame(score)\n",
        "\n",
        "# View the dataframe\n",
        "score_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OulpW1xqZ81L",
        "colab_type": "text"
      },
      "source": [
        "The aggregated scores for each sentiment is displayed here.\n",
        "\n",
        "The score of 146 for anger indicates that 146 words in the corpus were classified under the emotion anger by the sentiment libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yXKkP65Z_Jr",
        "colab_type": "text"
      },
      "source": [
        "Convert the rownames containing the sentiment heads into a column and use `cbind()` to combine this column with the sentiment scores.\n",
        "\n",
        "Also, set the row names for this new dataframe to `\"NULL\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7JiHC06aBJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert row names into 'sentiment' column and combine with sentiment scores\n",
        "score_df2 <- cbind(sentiment = row.names(score_df),  \n",
        "\t\t\t\t  score_df, row.names = NULL)\n",
        "\n",
        "# View the dataframe\n",
        "print(score_df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQqf9OGIaC5D",
        "colab_type": "text"
      },
      "source": [
        "We can now see a data frame with sentiments in one column and their respective scores in the second column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzaiFAh1aEb0",
        "colab_type": "text"
      },
      "source": [
        "**Step 3: Visualize sentiment scores and interpret customer perceptions**\n",
        "\n",
        "X-axis and Y-axis take the values `\"sentiment\"` and `\"score\"` respectively and fill is set to `\"sentiment\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYDkLpp8aGrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the sentiment scores\n",
        "ggplot(data = score_df2, aes(x = sentiment, y = score, fill = sentiment)) +\n",
        "  \t   geom_bar(stat = \"identity\") +\n",
        "       theme(axis.text.x = element_text(angle = 45, hjust = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P52nqP6iaI1J",
        "colab_type": "text"
      },
      "source": [
        "#### It is interesting to see that the positive sentiments collectively outnumber the negative ones. The high score on positive emotions, trust, and anticipation augurs well for the brand.\n",
        "\n",
        "#### Sentiment analysis is useful in social media monitoring since it gives an overview of people's sentiments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNV28QxgaJiF",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<center><h1> Q&A 5</h1> </center>\n",
        "\n",
        "---"
      ]
    }
  ]
}